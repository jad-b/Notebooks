{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacenter Outages\n",
    "\n",
    "#### 70% of all outages are caused by human error__\n",
    "* Siren noise damaging disk drives\n",
    "* Technicians shutting down the wrong system\n",
    "\n",
    "We'll follow with some examples of outages.\n",
    "\n",
    "## AWS \n",
    "* 2011 Apr 21\n",
    "* Down for >= 3.5 days\n",
    "    * Took out Reddit, FourSquare, more\n",
    "\n",
    "### Datacenter Model\n",
    "* __Regions__ Datacenters\n",
    "* __Availability Zones__ Different racks with a datacenter\n",
    "    * Can be configured to replicate data between zones in a region\n",
    "* __EBS__ Mountable storage \"devices\", accessible from EC2 instances\n",
    "    * 1 EBS volume runs inside an AZ\n",
    "    * Two networks:\n",
    "        1. Primary used for EC2 and EBS *control plane* traffic\n",
    "            * __control plane__ CRUD ops on volumes\n",
    "        1. Secondary used for *overflow*\n",
    "            * __overflow__ excess traffic from the primary\n",
    "    * Control information (metadata) replicated across zones (availability)\n",
    "* EBS volumes replicated for durability\n",
    "    * Each volume has a primary replica\n",
    "    * If out of sync or failure, replicas do an aggressive re-replication of data\n",
    "    \n",
    "### The story\n",
    "* 0047: Routine primary network capacity upgrade in an us-east-1 AZ\n",
    "    * Operator shifted off several primary n/w routers to other primary n/w routes\n",
    "    * __Critical Error__ *Someone* (*Bob*) moved primary router traffic to a secondary n/w router\n",
    "    * Secondary n/w routers can't handle primary traffic, so they become overwhelmed\n",
    "    * Left many EBS volumes without a connection to their replica on the primary n/w\n",
    "* Team discovered error and rolls it back\n",
    "    * __Error 2__ Due to n/w partitioning, many replicas thought they had no replica\n",
    "        * Began aggressive re-mirroring\n",
    "        * Flooded of mirroring used up available n/w capacity\n",
    "        * Began *looping*: Replicas were unable to verify replicas due to no n/w bandwidth, so they began trying to re-mirror elsewhere, deadlocking the n/w\n",
    "            * 13% of all EBS volumes\n",
    "    * This left no n/w capacity for Control Plane operations\n",
    "        * Again, control plane is used for CRUD operations on volumes, not actual data transfer\n",
    "        * Unable to serve \"create volume\" API requests for EBS\n",
    "        * Control plane ops have a long time-out; began backing up on the queue\n",
    "        * Once thread pool queue filled up, control plane begins rejecting \"create volume\" requests\n",
    "        * First customer-facing sign of difficulties\n",
    "* 0240: Team disables all \"Create Volume\" API requests\n",
    "* 0250: Error rates and latencies for EBS APIs start to recover\n",
    "    * Two things\n",
    "        * Primaries searching for replicas *still* kept consuming n/w capacity\n",
    "        * A race condition existed in EBS code\n",
    "            * Only triggered in high request rates\n",
    "            * Caused more node failures\n",
    "* 0530: Error rates and latencies increase *again*\n",
    "    * Some more background\n",
    "        * EBS re-mirroring is a negotiation between an EC2 node, an EBS node, and the EBS control plane\n",
    "            * race condition started causing EBS nodes to fail\n",
    "            * negotiation rates increased\n",
    "            * More EBS nodes failed as a result\n",
    "            * \"Brown-out\" of EBS API functionalities\n",
    "                * EBS isn't completely shut down, but large areas of functionality are going off-line\n",
    "* 0820: Team starts disabling all communications between EBS cluster in affected AZ and EBS control plane\n",
    "    * Shut down all EBS API operations in AZ\n",
    "* 1130: Team learns how to prevent EBS servers in AZ from futile re-mirroring\n",
    "    * AZ slowly recovering\n",
    "* Customers still getting high error rates for new EBS-backed EC2 instances until 1200\n",
    "    * A new EBS control plane API had recently been launched\n",
    "    * Its error rates were being shadowed by the recent troubles\n",
    "* 1200: No *new* volumes are getting stuck\n",
    "    * 13% volume still stuck\n",
    "* April 24 1200: All but 1.04% volumes had been recovered\n",
    "    * 0.07% EBS volumes could *not* be recovered\n",
    "\n",
    "### Lessons\n",
    "* Errors often begin with human error\n",
    "    * Operator moving primary n/w traffic to secondary n/w router\n",
    "* Lollapalooza effet\n",
    "    * Many other factors combine to cause a much *larger* situation\n",
    "    \n",
    "* Prevention\n",
    "    * Step-by-step protocol for n/w upgrades\n",
    "    * Higher capacity in secondary n/w\n",
    "    * EBS back-off timeout instead of aggressive re-mirroring \n",
    "    * Fix the race condition in the code\n",
    "    * Incentivize users to take advantage of multiple AZs within a region\n",
    "    * Improve dashboard for displaying state of customer systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook\n",
    "* 2010 Sep 23\n",
    "\n",
    "\n",
    "### Datacenter Model\n",
    "* Data stored in a *persistent store*, and *cache*\n",
    "    * __Persistent store__ many servers\n",
    "    * __Cache__ many servers running a distributed cache system\n",
    "* Automated system for verifying configuration data in cache\n",
    "    * Automatically replaces invalid cache values from persistent store (store)\n",
    "    \n",
    "### The Story\n",
    "* Sep 23: Invalid change saved to store\n",
    "    * All cache servers saw invalid value\n",
    "    * Flood of queries to DB cluster\n",
    "        * 100K's QPS\n",
    "* Team fixes invalid configuration in store\n",
    "* But, when a cache server receives an error from the DB, it marks it as invalid and deletes the cache entry\n",
    "    * Error here means failure to respond\n",
    "    * Cache server sends more queries\n",
    "    * Query escalation\n",
    "* Turn off FB website\n",
    "* Halt traffic to DB cluster\n",
    "* Slowly allow users back online\n",
    "* Took until later in day for site to return\n",
    "\n",
    "### Lessons\n",
    "* New config system design required\n",
    "* Back off instead of aggressive retry when resource is unavailable.\n",
    "    * Exponential backoff\n",
    "        * Used in TCP, 802.11\n",
    "        * Wait twice as long as last time\n",
    "            * $t = 2 * t_{prev}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Planet Outage\n",
    "\n",
    "* 2008 May 31\n",
    "* 4th largest web hosting company\n",
    "* Hosted 22k website\n",
    "\n",
    "\n",
    "* 1800: Explosion in H1 Houston DC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
